{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6971aa39-60a2-4381-8ab9-0f0cb2d236c5",
   "metadata": {},
   "source": [
    "状态空间用卡尔曼滤波估计的简单例子\n",
    "https://janelleturing.medium.com/advanced-time-series-analysis-state-space-models-and-kalman-filtering-3b7eb7157bf2\n",
    "时变参数状态空间模型与R应用\n",
    "https://statisticssu.github.io/STM/tutorial/statespace/statespace.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208c8511-493c-457c-a9d6-d948f9e4ec19",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpmath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mp\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m det\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minimize, least_squares, rosen, rosen_der, rosen_hess, Bounds,check_grad,approx_fprime\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mpmath'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "from mpmath import mp\n",
    "from scipy.linalg import det\n",
    "from scipy.optimize import minimize, least_squares, rosen, rosen_der, rosen_hess, Bounds,check_grad,approx_fprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8a380b-8d39-468f-85c4-529ee2c8b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLFA:\n",
    "    def __init__(self,mY,iP,iQ):\n",
    "        self.Y = mY\n",
    "        self.p = iP\n",
    "        self.q = iQ\n",
    "         \n",
    "        self.theta0 = self.__guess()   #初始值\n",
    "        self.theta = self.theta0       #设置当前theta\n",
    "    #s\n",
    "    def __guess(self):\n",
    "        N = self.Y.shape[0]\n",
    "        beta = np.ones([N-1,1])                                                  #因为GDP的载荷因子被设为1，所以beta估计值少1\n",
    "        theta = beta                                                             # beta：0到 N-2行，共N-1行\n",
    "        if self.p>0:\n",
    "            phi_f = np.zeros([1,self.p])\n",
    "            vphi_f = phi_f.reshape(-1,1)\n",
    "            theta = np.concatenate((theta,vphi_f),axis=0)                       #phi_f： N-1 到 N-1+p-1行 共p行 \n",
    "        if self.q >0:\n",
    "            phi_u = np.zeros([N,self.q])\n",
    "            vphi_u = phi_u.reshape(-1,1) #共N*q行\n",
    "            theta = np.concatenate((theta,vphi_u),axis=0)                       #phi_u： N-1+p 到 N-1+p+N*q-1 行 共N*q 行\n",
    "        dsig_11 = 0.5* np.ones([1,1]) \n",
    "        vsig_22 = 0.5* np.ones([N,1])\n",
    "        theta = np.row_stack((theta,dsig_11,vsig_22))                           #variance named \"sig\": 从 N-1+p+N*q 到 N-1+p+N*q+N行 共1+N行\n",
    "        theta = theta.flatten() \n",
    "        return theta                                                            # 从0到 N-1+p+q+N 行，共 N-1+p+q+N+1 行 \n",
    "    \n",
    "    def dfm(self,theta,N):         \n",
    "        cbeta = N - 1\n",
    "        cphi_f =  self.p\n",
    "        cphi_u = N *  self.q\n",
    "        cphi = cphi_f + cphi_u\n",
    "        ctheta = len(theta)\n",
    "        \n",
    "        # Ensure dimensions match when concatenating\n",
    "        beta = np.row_stack((np.array([1]), theta[0:cbeta].reshape(-1, 1)))   # 提取theta的0到 cbeta-1行 共cbeta-1+1 = N-1行，再加上1这一行，beta共N行\n",
    "        vphi_f = np.zeros([0,0])\n",
    "        #print(vphi_f.shape)=(0,0)\n",
    "        if  self.p > 0:\n",
    "            vphi_f0 = theta[cbeta:cbeta + cphi_f].T                           # 提取theta 从cbeta 到 cbeta+cphi_f-1行 共 cphi_f-1+1 = p 行 \n",
    "            vphi_f = np.array(vphi_f0).reshape(-1)\n",
    "            #print(vphi_f.shape)\n",
    "        if  self.q > 0:\n",
    "            element = np.array(theta[cbeta + cphi_f:cbeta + cphi_f + N])      #提取 theta 从 cbeta+cphi_f 到 cbeta+cphi_f+N-1行 共 N-1+1 = N 行\n",
    "            mphi_u = np.diagflat(element)\n",
    "                \n",
    "            if  self.q > 1:\n",
    "                for i in range(2,  self.q + 1):\n",
    "                    start_index = cbeta + cphi_f + (i - 1) * N\n",
    "                    end_index = cbeta + cphi_f + i * N\n",
    "                    element = theta[start_index:end_index]                     #切片theta 从 ...+N 到 ...+2N 共N+1-1=N行\n",
    "                    amphi_u_emp = np.diagflat(element)\n",
    "                    mphi_u = np.hstack((mphi_u, amphi_u_emp))\n",
    "                    \n",
    "        element = theta[cbeta + cphi]  # Ensure element is a scalar for dsig_11  # 切片theta 第cbeta+cphi+1行（因为从0开始的）\n",
    "        dsig_11 = np.array([[np.abs(element)]])  # Create a 2D array for np.diag\n",
    "        element = theta[cbeta + cphi + 1:ctheta]\n",
    "        msig_22 = np.diagflat(element)\n",
    "        return beta, vphi_f, mphi_u, dsig_11, msig_22\n",
    "\n",
    "    def ssr(self,N,N_1,beta, vphi_f, mphi_u, dsig_11, msig_22):\n",
    "        N_2 = N -N_1\n",
    "        cbeta = N\n",
    "        cbeta_1 = N_1\n",
    "        csta = 5+5*N\n",
    "        \n",
    "        F = np.zeros([csta,csta])\n",
    "        df = pd.DataFrame(F)\n",
    "        F[1:5,0:4]=np.identity(4)\n",
    "        #df.loc[1:4,0:3] = np.eye(4)                                  # row[1-4] column[0-3] (including the ending points)\n",
    "        F[5+N:5+5*N,5:5+4*N]== np.identity(4*N)\n",
    "        #df.loc[5+N:5+5*N-1,5:5+4*N-1] = np.identity(4*N)\n",
    "        if self.p>0:\n",
    "            F[0,0:self.p] =vphi_f                             # vphi_f = [phi_f,1  ... phi_f,p]\n",
    "            #print(F[0,0:p].shape)\n",
    "        if self.q>0:\n",
    "            F[5:5+N,5:5+(self.q*N)]=mphi_u \n",
    "        #print(F)\n",
    "            \n",
    "        G = np.zeros([csta,1+N])  \n",
    "        G[0][0]=1\n",
    "        df = pd.DataFrame(G)\n",
    "        df.loc[5:5+N-1,1:1+N-1]=np.identity(N)\n",
    "        #print(G)\n",
    "            \n",
    "        H_1 = [0]\n",
    "        if N_1>0:\n",
    "            beta1=beta[0:cbeta_1]   # 切片包含起止节点不包含终止节点\n",
    "            H_1 = np.zeros([N_1,csta])\n",
    "            H_1[:,0:1]=(1/3)*beta1\n",
    "            H_1[:,1:2]=(2/3)*beta1\n",
    "            H_1[:,2:3]=beta1\n",
    "            H_1[:,3:4]=(2/3)*beta1\n",
    "            H_1[:,4:5]=(1/3)*beta1\n",
    "            H_1[:,5:5+N_1]=(1/3)*np.identity(N_1)\n",
    "            H_1[:,5+N:5+N+N_1]=(2/3)*np.identity(N_1)\n",
    "            H_1[:,5+2*N:5+2*N+N_1]=np.identity(N_1)\n",
    "            H_1[:,5+3*N:5+3*N+N_1]=(2/3)*np.identity(N_1)\n",
    "            H_1[:,5+4*N:5+4*N+N_1]=(1/3)*np.identity(N_1)\n",
    "            \n",
    "        beta2=beta[cbeta_1:cbeta]  # cebta_1 = N_1\n",
    "        H_2 = np.zeros([N_2,csta])\n",
    "        H_2[:,0:1]=beta2\n",
    "        H_2[:,5+N-N_2:5+N]= np.identity(N_2)\n",
    "        \n",
    "        msig_vv = np.identity(1+N)\n",
    "        msig_vv[0][0]= dsig_11[0][0]\n",
    "        msig_vv[1:1+N,1:1+N]=msig_22\n",
    "        return F,G,H_1,H_2,msig_vv\n",
    "\n",
    "    def kf(self,F,G,H_1,H_2,msig_vv):\n",
    "        Y = self.Y\n",
    "        N = Y.shape[0]\n",
    "        N_1 =  N_1 = np.sum(np.isnan(Y[:, 0]))\n",
    "        cobs = Y.shape[1]\n",
    "        csta = 5 + 5*N\n",
    "        \n",
    "        lnl = np.zeros([cobs,1])\n",
    "        index_u = np.zeros([cobs,1])\n",
    "        s_u = np.zeros([csta,1])      # state space \n",
    "        p_u = np.zeros([csta,csta])   #vairance and covariance \n",
    "    \n",
    "        def trans(x):\n",
    "            result = np.transpose(x)\n",
    "            return result\n",
    "        \n",
    "        for t in range(cobs):\n",
    "            #prediction    \n",
    "            s_p = F @ s_u  \n",
    "            p_p = F @ p_u @ trans(F) + G @ msig_vv @ trans(G)          \n",
    "                    \n",
    "            #log-likelihood\n",
    "            y0 = np.array(Y[:,t])\n",
    "            y = y0.reshape(-1,1)\n",
    "            y = np.matrix(y)\n",
    "            H = H_2\n",
    "            sig_ww = np.zeros([N,N])\n",
    "            if N_1 >0:\n",
    "                H = np.vstack((H_1,H_2))\n",
    "                if np.any(np.isnan(y)):\n",
    "                    df = pd.DataFrame(y)\n",
    "                    y = df.fillna(0)\n",
    "                    rows, cols = H_1.shape\n",
    "                    H_zero = np.zeros([rows,cols])\n",
    "                    H = np.vstack((H_zero,H_2))\n",
    "                    sig_ww[0:N_1,0:N_1] = np.identity(N_1)\n",
    "            \n",
    "            e = y-H @ s_p                                 # 向前一步的预测误差\n",
    "            sig_ee = H @ p_p @ trans(H) + sig_ww          # 向前一步预测误差的协方差矩阵\n",
    "            sign, determinant = np.linalg.slogdet(sig_ee)\n",
    "            if sign != 1:   \n",
    "                lnl[t] = np.inf\n",
    "            else:\n",
    "                try:\n",
    "                    inv_sig_ee = np.linalg.inv(sig_ee)\n",
    "                    lnl[t] = - (N / 2) * np.log(2 * np.pi) - 0.5 * mp.det(mp.matrix(sig_ee)) - 0.5 * (e.T @ inv_sig_ee @ e)\n",
    "                except np.linalg.LinAlgError:\n",
    "                    lnl[t] = np.inf\n",
    "                \n",
    "            # updating\n",
    "            gain = p_p @ trans(H) @ np.linalg.inv(H @ p_p @ trans(H) + sig_ww)  #卡尔曼增益\n",
    "            s_u = s_p + gain @ (y-H @ s_p)                                      \n",
    "            p_u = p_p - gain @ H @ p_p\n",
    "            df = pd.DataFrame(index_u)\n",
    "            df.loc[t,:] = s_u[0]  #提取更新方程中计算的f_t\n",
    "        return lnl, index_u\n",
    "\n",
    "    def loglikelihood(self,theta):\n",
    "        Y = self.Y\n",
    "        N = Y.shape[0]\n",
    "        N_1 = np.sum(np.isnan(Y[:, 0]))\n",
    "        \n",
    "        beta, vphi_f, mphi_u, dsig_11, msig_22 = self.dfm(theta, N)\n",
    "        F, G, H_1, H_2, msig_vv = self.ssr(N,N_1,beta, vphi_f, mphi_u, dsig_11, msig_22)\n",
    "        lnl, index_u = self.kf(F,G,H_1,H_2,msig_vv)\n",
    "\n",
    "        valid_lnl = lnl[np.isfinite(lnl)]  #isfinite\n",
    "        if len(valid_lnl) ==0:\n",
    "            return np.inf\n",
    "        MLE = -np.sum(valid_lnl,axis=0)\n",
    "        print(f\"Current theta: {theta}\")\n",
    "        print(f\"Current log-likelihood: {MLE}\")\n",
    "        return MLE\n",
    "\n",
    "\n",
    "    def theta_fixed(self):\n",
    "            theta_fixed = self.theta0\n",
    "            n = self.p+self.q\n",
    "            for i in range(n):\n",
    "                theta_fixed[i]=0.5\n",
    "            return theta_fixed\n",
    "        \n",
    "    def estimate(self):\n",
    "        N = Y.shape[0]\n",
    "        cobs = Y.shape[1]\n",
    "\n",
    "        history = {'parameters': [], 'values': []} \n",
    "        def make_callback(history):\n",
    "            def callback(theta):\n",
    "                \"\"\"\n",
    "                Callback function to monitor optimization progress.\n",
    "                theta: Current parameter values.\n",
    "                \"\"\"\n",
    "                # 保存当前参数值\n",
    "                history['parameters'].append(theta)\n",
    "                \n",
    "                # 计算并保存当前目标函数值\n",
    "                current_value = self.loglikelihood(theta)\n",
    "                history['values'].append(current_value)\n",
    "                \n",
    "                # 打印信息\n",
    "                print(f\"Iteration {len(history['values'])}: Current function value = {current_value}\")\n",
    "            return callback\n",
    "\n",
    "         # 创建 callback 函数\n",
    "        callback = make_callback(history)\n",
    "        \n",
    "        result = minimize( fun=lambda theta: self.loglikelihood(theta),\n",
    "                            x0=self.theta0, \n",
    "                            method='BFGS',\n",
    "                            jac = None,\n",
    "                            options={'disp': True ,'maxiter': 1000,'gtol':1e-3,'eps':1e-03},\n",
    "                            callback = callback\n",
    "                            )\n",
    "        self.theta_result = result.x\n",
    "        #optimal_lnl_value = -result.fun    \n",
    "        #dlnl = cobs * optimal_lnl_value\n",
    "        dlnl = -result.fun\n",
    "        cpar = N + self.p + N * self.q + N\n",
    "        dAIC = (dlnl - cpar) / cobs\n",
    "        dBIC = (dlnl - cpar * np.log(cobs) / 2) / cobs\n",
    "        print(f\"the value of p,q,lnl,AIC,BIC is {self.p, self.q, dlnl, dAIC, dBIC}\")\n",
    "        return self.theta_result\n",
    "        \n",
    "    def index_u(self,theta):\n",
    "        \n",
    "        N = Y.shape[0]\n",
    "        rows_with_nan = df.isna().any(axis=1)\n",
    "        N_1 = rows_with_nan.sum()\n",
    "        \n",
    "        beta, vphi_f, mphi_u, dsig_11, msig_22 = self.dfm(theta, N)\n",
    "        F, G, H_1, H_2, msig_vv = self.ssr(N,N_1,beta, vphi_f, mphi_u, dsig_11, msig_22)\n",
    "        lnl, index_u = self.kf(F,G,H_1,H_2,msig_vv)\n",
    "        \n",
    "        return index_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8b05bd-69e4-45f6-bcd0-fc2a307b13bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:/MixedData/LargeStateSpace/中国宏观变量数据-CEIC2005.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF:/MixedData/LargeStateSpace/中国宏观变量数据-CEIC2005.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain2005\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m},axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DFM\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DFM\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DFM\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DFM\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:/MixedData/LargeStateSpace/中国宏观变量数据-CEIC2005.xlsx'"
     ]
    }
   ],
   "source": [
    "data= pd.read_excel(r'F:/MixedData/LargeStateSpace/中国宏观变量数据-CEIC2005.xlsx',index_col=False,sheet_name='main2005') \n",
    "df=pd.DataFrame(data)\n",
    "df.drop(labels={'Unnamed: 0'},axis=1,inplace=True)\n",
    "\n",
    "Y0 = df.values \n",
    "Y = Y0.T\n",
    "\n",
    "df=pd.DataFrame(Y)\n",
    "N = Y.shape[0]\n",
    "rows_with_nan = df.isna().any(axis=1)\n",
    "N_1 = rows_with_nan.sum()\n",
    "p=1\n",
    "q=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ab4d6a-000b-4763-9017-1c5b64b8b2fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLFA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mlfa \u001b[38;5;241m=\u001b[39m MLFA(Y,p,q)\n\u001b[0;32m      2\u001b[0m optimal_theta \u001b[38;5;241m=\u001b[39m mlfa\u001b[38;5;241m.\u001b[39mestimate()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe optimal theta: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimal_theta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MLFA' is not defined"
     ]
    }
   ],
   "source": [
    "mlfa = MLFA(Y,p,q)\n",
    "optimal_theta = mlfa.estimate()\n",
    "print(f\"the optimal theta: {optimal_theta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0eadb-0aec-4907-8d4b-3e551cdd444e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
